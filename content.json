{"posts":[{"title":"DETR","text":"概要説明DETR (DEtection TRansformer) は、物体検出（object detection）タスクにおける新しいアプローチとして、2020年に Facebook AI（現 Meta AI）によって発表されたアルゴリズムです。DETR は、従来の物体検出モデルとは異なり、トランスフォーマーベースのアーキテクチャを使用することで、検出と分類のプロセスを大幅に簡素化しています。論文：https://arxiv.org/pdf/2005.12872 DETR の特徴Transformer Architecture自然言語処理で成果を挙げたTransformerを画像処理に応用しています。入力画像をエンコーダーで特徴量に変換し、トランスフォーマーデコーダーが物体の位置（bbox）とClass labelを予測できます。 End-to-endのアプローチ従来の物体検出では、アンカー生成や後処理（NMS: Non-Maximum Suppression）などの手作業のステップが必要でしたが、DETR ではこれらが不要となります。これにより、シンプルで効率的な学習が可能になっています。 マルチタスク(物体検出と分類を同時に実行)DETR は、画像中の物体の位置を検出し、それらを分類するプロセスを統一されたフレームワーク内で行います。 環境の準備DETR を動かすには、Python と PyTorch の環境が必要です。以下の手順で準備を進めます。 Python 環境の作成 12345# 仮想環境の作成（例: conda）conda create -n detr_env python=3.9 -yconda activate detr_envPyTorch のインストールPyTorch を CUDA 対応でインストールします（GPU 使用の場合）。 123456コードをコピーする# GPU 用 PyTorch (CUDA 11.7) のインストールpip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117# CPU 用 PyTorch のインストール（GPU がない場合）pip install torch torchvision torchaudio DETRインストール早速、Git clone を実行して、確認しましょう。 12345git clone https://github.com/facebookresearch/detr.gitcd detr# 必要なライブラリをインストールpip install -r requirements.txt DETR を使用した推論それでは、COCO データセットを使用した事前学習済みモデルで物体検出を行います。 detr_inference.py ファイルを作成して推論コードを準備します。 1234567891011121314151617181920212223242526import torchfrom transformers import DetrForObjectDetection, DetrImageProcessorfrom PIL import Imageimport requests# 事前学習済みモデルとプロセッサのロードprocessor = DetrImageProcessor.from_pretrained(&quot;facebook/detr-resnet-50&quot;)model = DetrForObjectDetection.from_pretrained(&quot;facebook/detr-resnet-50&quot;)# 入力画像を用意url = &quot;https://images.unsplash.com/photo-1593642532973-d31b6557fa68&quot;image = Image.open(requests.get(url, stream=True).raw)# 推論inputs = processor(images=image, return_tensors=&quot;pt&quot;)outputs = model(**inputs)# 物体検出結果を取得results = processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=[image.size])# 検出結果を出力for result in results: for score, label, box in zip(result[&quot;scores&quot;], result[&quot;labels&quot;], result[&quot;boxes&quot;]): print(f&quot;Label: {model.config.id2label[label.item()]}, Score: {score.item():.3f}, Box: {box.tolist()}&quot;) 保存して実行します。 1python detr_inference.py DETRのTraining1python -m torch.distributed.launch --nproc_per_node=1 --use_env main.py --coco_path /workspaces/bev-playground/dataset/coco","link":"2024/12/19/DETR/"},{"title":"add-mermaind","text":"環境セットアップhexo-filter-mermaid-diagramsのインストール1npm install hexo-filter-mermaid-diagrams --save Mermaidの_config.ymlの設定12345mermaid: enable: true version: \"7.1.2\" # Available themes: default | dark | forest | neutral theme: default Mermaidの読み込みhexo-theme-icarus/layout/common/scripts.jsxに以下を追加する 1&lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.4.0/mermaid.min.js\"&gt;&lt;/script&gt; ダイアグラム図作成フローチャート図12345graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; click D \"https://google.com\"; シーケンス図1234567891011sequenceDiagram participant Alice participant Bob Alice-&gt;&gt;John: Hello John, how are you? loop Healthcheck John-&gt;&gt;John: Fight against hypochondria end Note right of John: Rational thoughts &lt;br/&gt;prevail... John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob: How about you? Bob--&gt;&gt;John: Jolly good! sequenceDiagram participant Alice participant Bob Alice-&gt;&gt;John: Hello John, how are you? loop Healthcheck John-&gt;&gt;John: Fight against hypochondria end Note right of John: Rational thoughts prevail... John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob: How about you? Bob--&gt;&gt;John: Jolly good! ガンチャート図123456789ganttdateFormat YYYY-MM-DDtitle Adding GANTT diagram to mermaidsection A sectionCompleted task :done, des1, 2014-01-06,2014-01-08Active task :active, des2, 2014-01-09, 3dFuture task : des3, after des2, 5dFuture task2 : des4, after des3, 5d gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d クラス図1234567891011121314classDiagramClass01 &lt;|-- AveryLongClass : CoolClass03 *-- Class04Class05 o-- Class06Class07 .. Class08Class09 --&gt; C2 : Where am i?Class09 --* C3Class09 --|&gt; Class07Class07 : equals()Class07 : Object[] elementDataClass01 : size()Class01 : int chimpClass01 : int gorillaClass08 &lt;--&gt; C2: Cool label classDiagram Class01 &lt;|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --&gt; C2 : Where am i? Class09 --* C3 Class09 --|&gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 &lt;--&gt; C2: Cool label Gitグラフ12345678910gitGraph commit commit branch develop commit commit commit checkout main commit commit gitGraph commit commit branch develop commit commit commit checkout main commit commit Quadrant Chart123456789101112131415quadrantChart title Reach and engagement of campaigns x-axis Low Reach --&gt; High Reach y-axis Low Engagement --&gt; High Engagement quadrant-1 We should expand quadrant-2 Need to promote quadrant-3 Re-evaluate quadrant-4 May be improved Campaign A: [0.3, 0.6] Campaign B: [0.45, 0.23] Campaign C: [0.57, 0.69] Campaign D: [0.78, 0.34] Campaign E: [0.40, 0.34] Campaign F: [0.35, 0.78] quadrantChart title Reach and engagement of campaigns x-axis Low Reach --&gt; High Reach y-axis Low Engagement --&gt; High Engagement quadrant-1 We should expand quadrant-2 Need to promote quadrant-3 Re-evaluate quadrant-4 May be improved Campaign A: [0.3, 0.6] Campaign B: [0.45, 0.23] Campaign C: [0.57, 0.69] Campaign D: [0.78, 0.34] Campaign E: [0.40, 0.34] Campaign F: [0.35, 0.78] Pie chart diagrams12345pie title Pets adopted by volunteers \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15 pie title Pets adopted by volunteers \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15 フローチャートflowchart A(開始) B(終了) 処理1 C[処理2] D{判断} E[処理2-2] F{{準備}} G1[/外部データ&lt;上にあると入力&gt;/] G2[/外部データ&lt;下にあると出力&gt;/] H[[定義&lt;マクロ&gt;]] I[(データベース)] J1((結合子A)) J2((結合子A')) K1[/ループ開始\\] K2[\\ループ終了条件式/] A --&gt; F F --&gt; K1 K1 --&gt; 処理1 処理1 --&gt; D D --&gt; E &amp; G1 E --&gt; H G1 --&gt; C --&gt; G2 G2 &amp; H --&gt; K2 --&gt; B H -.- J1 J2 --&gt; マクロ内容開始 --- I --- マクロ内容終了 --&gt; J2","link":"2024/12/27/add-mermaind/"},{"title":"bevformer","text":"概要説明","link":"2024/12/27/bevformer/"},{"title":"create-hexo-website","text":"Generate new articleCreate new post 1hexo new \"first post\" Create a new page on Hexo or Algorithm. 12hexo new page hexohexo new page algorithm Run Hexo server locally1hexo server Generate the Website12hexo cleanhexo generate Deploy your Website to GithubPush source to public 1hexo deploy","link":"2024/12/27/create-hexo-website/"},{"title":"BEVDet","text":"概要説明マルチカメラの3D 既存技術より優れキー技術 Image-view Encoder View Transformer","link":"2024/12/28/BEVDet/"},{"title":"install-hexo","text":"Hexo インストール123hexo init &lt;folder&gt;cd &lt;folder&gt;npm install hexo-theme-icarusのインストール1npm install -S hexo-theme-icarus hexo-renderer-inferno _config.yml ファイル1theme: icarus もしくは 1hexo config theme icarus","link":"2024/12/27/install-hexo/"},{"title":"CaDDN","text":"概要説明Categorical Depth Distribution Network for Monocular 3D Object DetectionCody Reading Ali Harakeh Julia Chae Steven L. WaslanderUniversity of Toronto Robotics Institute https://arxiv.org/pdf/2103.01100","link":"2024/12/28/CaDDN/"},{"title":"basic-cnn-models","text":"Book list of Deep learningお世話になった本入門本として以下2冊で十分かと思います 深層学習(岡谷 貴之 著) 2015年 ゼロから作るDeep Learning - Pythonで学ぶディープラーニングの理論と実装(斎藤 康毅 著) 2016年 CNNの基本Loss関数Neural Networkは最適なパラメータ(Weightとbias)を見つけるため、学習で損失関数が最小値を取るとき 2乗和誤差 クロースエントロピー誤差 パラメータ更新https://github.com/j-w-yun/optimizer-visualization SGD(確率的勾配降下法) Momentum 勾配の累積 (モメンタム更新): パラメータの更新: AdaGrad 勾配の累積二乗和: パラメータの更新: Adam 勾配の移動平均 (モーメント計算): バイアス補正: パラメータの更新: 正則化モデルが過学習（オーバーフィッティング）するのを防ぐため目的にパラメータに何らかの制約を課すことですよく使われる正則化手法は以下です。 制約付き最適化(KKT条件から導く) L2正則化(Ridge回帰):寄与が小さい重みを抑える L1正則化(Lasso回帰): 寄与が小さい重みをゼロにする Dropout データ拡張 Early Stopping バッチ正則化 Dataset画像 MNIST ImageNet COCO2017 Cityscapes KITTI nuScenes Megaface WaymoOpen 音声 LibriSpeech AudioSet Common Voice Early models モデル 発表年 学会または発表場所 論文タイトル URL AlexNet 2012 NIPS 2012 (現NeurIPS) ImageNet Classification with Deep Convolutional Neural Networks AlexNet VGG16 2014 arXiv (未発表) Very Deep Convolutional Networks for Large-Scale Image Recognition VGG16 GoogLeNet 2014 CVPR 2015 (2014年発表) Going Deeper with Convolutions GoogLeNet ResNet 2015 CVPR 2016 (2015年発表) Deep Residual Learning for Image Recognition ResNet DenseNet 2016 CVPR 2017 (2016年発表) Densely Connected Convolutional Networks DenseNet Application modelsDetection 論文名 発表時間 発表者 発表組織 URL R-CNN 2013/11 Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik UC Berkeley rink Fast R-CNN 2015/04 Ross Girshick Microsoft Research rink Faster R-CNN 2015/06 Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun Microsoft Research rink YOLO 2015/06 Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi University of Washington, Allen Institute for AI rink SSD 2015/12 Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg Google Research, University of North Carolina, Chapel Hill rink RetinaNet 2017/08 Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, Piotr Dollár Facebook AI Research rink YOLOv3 2018/4 Joseph Redmon, Ali Farhadi University of Washington, Allen Institute for AI rink CenterNet 2019/05 Xingyi Zhou, Dequan Wang, Philipp Krähenbühl UT Austin rink YOLOv4 2020/04 Alexey Bochkovskiy, Chien-Yao Wang, Hong-Yuan Mark Liao Independent &amp; Academia Sinica rink YOLOv5 2020/10 Ultralytics Team Ultralytics rink EfficientDet 2020/03 Mingxing Tan, Ruoming Pang, Quoc V. Le Google Research rink DETR 2020/05 Nicolas Carion, Francisco Massa, Gabriel Synnaeve, et al. Facebook AI Research rink Deformable DETR 2020/10 Xiaohang Zeng, Xizhou Zhu, Yue Cao, et al. Microsoft Research Asia rink Segmentation 論文名 発表時間 発表者 発表組織 URL FCN 2014/11 Jonathan Long, Evan Shelhamer, Trevor Darrell UC Berkeley rink U-Net 2015/05 Olaf Ronneberger, Philipp Fischer, Thomas Brox University of Freiburg rink SegNet 2015/11 Vijay Badrinarayanan, Alex Kendall, Roberto Cipolla University of Cambridge rink DeepLab 2016/06 Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L. Yuille Google DeepMind &amp; University of Maryland rink PSPNet 2016/12 Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia Chinese University of Hong Kong rink Mask R-CNN 2017/03 Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick Facebook AI Research rink DeepLabv3 2017/09 Liang-Chieh Chen, George Papandreou, Florian Schroff, Hartwig Adam Google Research rink Semantic FPN 2018/02 Xiaoxiao Li, Ross Girshick, Kaiming He, Piotr Dollár Facebook AI Research rink DeepLabv3+ 2018/03 Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, Hartwig Adam Google Research rink HRNet 2019/04 Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, et al. Microsoft Research Asia rink DETR 2020/05 Nicolas Carion, Francisco Massa, et al. Facebook AI Research rink ViT (Vision Transformer) 2020/06 Alexey Dosovitskiy, Lucas Beyer, et al. Google Research rink PointRend 2020/03 Alexander Kirillov, Yuxin Wu, Kaiming He, Ross Girshick Facebook AI Research rink Swin Transformer 2021/03 Ze Liu, Yutong Lin, Yue Cao, et al. Microsoft Research Asia rink SegFormer 2021/06 Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo CUHK &amp; NVIDIA Research rink Swin-UNet 2021/07 Hu Cao, Yue Cao, Zheng Zhang, Ming-Hsuan Yang, Ran He, Jian Yang Nanjing University of Science and Technology rink MaskFormer 2021/10 Bowen Cheng, Alex Schwing, Alexander Kirillov Facebook AI Research rink Segment Anything 2023/04 Alexander Kirillov, Eric Mintun, et al. Meta AI rink","link":"2024/12/28/basic-cnn-models/"}],"tags":[{"name":"BEV","slug":"BEV","link":"tags/BEV/"}],"categories":[{"name":"ML","slug":"ML","link":"categories/ML/"},{"name":"Hexo","slug":"Hexo","link":"categories/Hexo/"}],"pages":[{"title":"neural chip","text":"コンパイラ最適化Layer Group1から4、5から8、8から12のように分けることができます。しかし、ここで重要なのは、これは実際には組み合わせの問題であるという点です。つまり、多くの異なる分け方が可能です。極端な例では、1から12をすべて1つのグループにする方法、または1から12を12個のグループに分け、各層を1つのグループにする方法があります。 もともとGPU上で一般的に行われていた方法は、各層を1つのグループに分ける方法でした。これは、各層を計算した後にDDRにStoreします。それを統合して次の層の計算を行うというプロセスに基づいています。 その後、グループ化が終わったら、次のステップとしてPruning操作を行います。この操作を通じて、効果が良くないことがわかった場合には、その部分を削除します。次に、Layer Groupを単位として指令の再配置（TilingやSchedule、Sherlockの割り当てなど）を行います。指令の再配置について後ほど説明します。 これらの操作がすべて完了した後、正常にプロセスが進む場合、それは「コンパイル可能」であることを意味します。しかし、グループ化の段階で必要なメモリサイズ(SRAMの容量よりはるか大きい)が大きすぎる場合、コンパイルできないことがあります。 そのため、CoreGenerator/Performance estimationを用いて予測を行うことで、最も処理時間が短いとなる効率的なグループ化を選定します。 Tilingの回数で探索する必要があります。 CodeGenの過程では：Tiling方向、Tiling回数、keep in SRAM Tilingのプロセスを制御する際には、反復計算の方向や回数、中間出力の結果をさらに計算に持ち込むかどうかといった、実行時に意思決定が必要な戦略を考慮する必要があります。これらの問題を解決するために、動的計画法（Dynamic Programming）を用いる方法を採用しています。 動的計画法を使って、最適なNLPのレイヤー分割を探索します。ただし、計算が爆発的に増加しないように、最大のレイヤー数を制限しています。例えば、最大50層までに制限するとします。この50層というのが、現実的に許容可能な上限になります。 具体例として、100層のモデルがあると仮定します。もし完全探索を行うと、非常に多くの試行回数が必要になりますが、EP（例えばEvolutionary Programming）などの手法を使うことで、試行回数を約5000回程度に減らせます。さらに、各グループ内で最大のOP数を制限すれば、試行回数をさらに減少させることも可能です。 しかし、これらの試行には、Tiling（タイル分割）、Schedule（スケジュール）、オーバーヘッドの削減といった部分は含まれていません。そのため、さらに極端な簡略化や最適化を行い、明らかに利益を生まない部分を削除する作業が必要です。 たとえば、Layer Groupを切り替える場合、Proof、Style、その他の要素を1つのグループにまとめたと仮定します。このとき、どのようにTilingを行うべきでしょうか？Tilingを行うことによって得られる利点は何でしょうか？このような問いは、多くの研究者や開発者が直面している課題であり、さまざまな場面で議論されています。 SchedulingSchedulingの過程では、演算容量の状況を考慮する必要があります。例えば、この場所で使用するクライアントソフトウェアがある場合、そのスケジュールがこの場所に割り当てられると、入力と出力の演算容量が収まらない可能性があります。その場合、仕方なく後回しにする必要がある場合もあります。 したがって、スケジューリング時には演算容量の配分を考慮する必要があります。当初、動的計画法DPを用いて、演算容量の配分は非常に簡単だと思われていました。例えば、等分する方法で調整する場合、各Tileのサイズを均一にすればよいと考えられていました。 しかし、現在ではモデルがますます複雑になり、このような状況が多様化しています。タイルのサイズもさまざまで、それに伴う状況も複雑になっています。時には、適切に分割できないことで、ある場所には収まるが、別の場所には収まらないといった事態が発生します。その結果、演算容量の配分アルゴリズムの複雑さが大幅に増大しているのが現状です。 コンパイラモデルLEAP(DSL for Efficient AI Programming) 例として、Input → ProPrcess → NeuralNetwork → PostProcess → Output Torch Core : DSL: Triton: C/C++: 123456789# example inputexample_inputs = np.none((1,224,224,3), dtype='int8')# convert to mlirmlir_module = traslate(model_pipeline, example_inputs)# compilebayes_module = convert(mlir_module, \"bayes\")compile(bayes_module, output='xxx.hbm)","link":"achieve/2024_12_27_neural-chip.html"},{"title":"hexo","text":"Installing Hexo Create Hexo website Adding Mermaind into Hexo","link":"hexo/index.html"},{"title":"Algorithm","text":"Vision-base自動運転研究の遷移（抜粋）Flowchart flowchart LR subgraph 2017. A([Transformer ....]) click A \"/2024/12/19/DETR/\"; end subgraph 2020.. A --&gt; B([DETR ...]) click B \"/2024/12/19/DETR/\"; A --&gt; C([ViT ...]) B --&gt; D([Deformable-DETR .....]) L([LSS ..]) end subgraph 2021.. D --&gt; E([DETR3D ...]) C --&gt; F([SwinTransformer .....]) L --&gt; Ca([CaDDN ...]) Ca --&gt; Be([BEVDet ...]) end subgraph 2022.. E --&gt; G([BEVFormer ...]) G --&gt; H([ST-P3...]) Be --&gt; Be4([BEVDet4D ..]) L --&gt; BeFu([BEVFusion ..]) end subgraph 2023.. H --&gt; I([UniAD...]) G --&gt; I B --&gt; J([MapTR...]) J --&gt; K([VAD...]) I --&gt; K G --&gt; K end 2017Transformer: Attention Is All You Need 点群ベースVoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection PointNetPointNet++ Frustrum PointNets VoxelNet PointPillars Basic Models","link":"algorithm/index.html"}]}